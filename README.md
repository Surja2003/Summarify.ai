# Sumrify - AI Document Summarization Platform

A modern, production-ready web application for AI-powered document summarization with hybrid NLP techniques (extractive + abstractive), keyword extraction, and interactive analytics.

## ğŸ¯ Features

  - Extractive (TF-IDF based)
  - Abstractive (Transformer models - optional)

## ğŸ› ï¸ Tech Stack

### Frontend

### Backend (Optional Enhancement)

## ğŸ“ Project Structure

```
sumrify/
â”œâ”€â”€ frontend/                 # React + TypeScript frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”‚   â”œâ”€â”€ utils/           # Utilities (summarizer.ts)
â”‚   â”‚   â”œâ”€â”€ types.ts         # TypeScript types
â”‚   â”‚   â””â”€â”€ App.tsx          # Main app component
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ backend/                 # FastAPI backend (optional)
â”‚   â”œâ”€â”€ main.py             # API routes
â”‚   â”œâ”€â”€ summarizer.py       # Summarization logic
â”‚   â”œâ”€â”€ parsers.py          # Document parsers
â”‚   â”œâ”€â”€ utils.py            # Utilities
â”‚   â””â”€â”€ requirements.txt    # Python dependencies
â”‚
â””â”€â”€ README.md
```

## ğŸš€ Setup & Installation

### Frontend Setup

1. **Navigate to frontend directory:**
   ```bash
   cd frontend
   ```

2. **Install dependencies:**
   ```bash
   npm install
   ```

3. **Start development server:**
   ```bash
   npm run dev
   ```

4. **Build for production:**
   ```bash
   npm run build
   ```

The frontend runs standalone and processes documents entirely in the browser using client-side NLP.

### Backend Setup (Optional)

The backend provides optional enhanced features like:

1. **Navigate to backend directory:**
   ```bash
   cd backend
   ```

2. **Create virtual environment:**
   ```bash
   python -m venv venv
   
   # Windows
   venv\Scripts\activate
   
   # macOS/Linux
   source venv/bin/activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Run the API server:**
   ```bash
   uvicorn main:app --reload
   ```

5. **API will be available at:**
   - http://localhost:8000
   - API docs: http://localhost:8000/docs

## ğŸ“¡ API Endpoints (Backend)

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | API information |
| GET | `/health` | Health check |
| POST | `/api/summarize` | Summarize single document |
| POST | `/api/summarize/batch` | Batch summarize multiple documents |
| POST | `/api/chat` | Chat with document |
| GET | `/api/history` | Get summarization history |
| POST | `/api/history` | Add to history |
| POST | `/api/export` | Export summary (TXT/PDF) |

## ğŸ¨ Frontend Usage

1. **Upload Documents:**
   - Click "Upload" or drag & drop files
   - Supports PDF, DOCX, TXT
   - Can paste text directly

2. **Configure Settings:**
   - **Speed Mode**: Fast (quick), Balanced (recommended), Thorough (detailed)
   - **Domain**: General, Academic, Legal, Journalistic
   - **Abstractive Refinement**: Enable for AI-enhanced summaries

3. **View Results:**
   - **Summary Tab**: Structured summary with main points
   - **Highlights Tab**: Key sentences with importance scores
   - **Keywords Tab**: Extracted important terms
   - **Analytics Tab**: Metrics and visualizations
   - **Chat Tab**: Ask questions about the document

4. **History:**
   - Access previous summarizations
   - Click to reload results

## ğŸ”§ Configuration

### Frontend Environment
No environment variables needed - runs standalone.

### ChatGPT-like Chat (Recommended)

The chat UI calls a lightweight serverless endpoint at `/api/chat`.

- If `OPENAI_API_KEY` is set (Vercel env var), responses use an OpenAI chat model (more ChatGPT-like).
- If it is not set (or the API is unreachable in local dev), the UI falls back to the built-in keyword-based responses.

Set these environment variables in Vercel (Project â†’ Settings â†’ Environment Variables):

```env
OPENAI_API_KEY=...your key...
OPENAI_MODEL=gpt-4o-mini
```

Notes:
- In local dev (`npm run dev`), `/api/chat` usually wonâ€™t exist unless you run via `vercel dev`; the UI will automatically fall back.

### Hugging Face (Free Hosted Models)

If you want a â€œno OpenAI keyâ€ option, you can use Hugging Faceâ€™s hosted inference API (free tier is typically rate-limited).

Set these environment variables (Vercel or local backend):

```env
HUGGINGFACE_API_TOKEN=...your token...
HUGGINGFACE_MODEL=HuggingFaceH4/zephyr-7b-beta
```

The chat endpoint will prefer `OPENAI_API_KEY` when present, otherwise it will try Hugging Face.

### Backend Environment (if using)
Create a `.env` file in the backend directory:

```env
# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# CORS Settings
CORS_ORIGINS=*

# Cache Settings
MAX_CACHE_SIZE=100

# Optional: OpenAI-backed chat (ChatGPT-like)
OPENAI_API_KEY=...your key...
OPENAI_MODEL=gpt-4o-mini
```

## ğŸ“Š Sample API Request

### Summarize Document

```bash
curl -X POST "http://localhost:8000/api/summarize" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Your document text here...",
    "settings": {
      "speedMode": "balanced",
      "domain": "general",
      "useAbstractive": false
    },
    "fileName": "document.txt"
  }'
```

### Response

```json
{
  "summary": "The main summary text...",
  "highlights": [
    {
      "sentence": "Important sentence 1...",
      "score": 0.85,
      "index": 0
    }
  ],
  "keywords": [
    {
      "word": "important",
      "score": 0.75
    }
  ],
  "sentenceScores": [...],
  "metrics": {
    "compressionRatio": 65,
    "originalSentences": 20,
    "summarySentences": 7,
    "processingTime": 1234
  },
  "fileName": "document.txt",
  "timestamp": "2025-12-19T...",
  "settings": {...}
}
```

## ğŸ¯ Algorithms

### Extractive Summarization

### Abstractive Refinement (Optional)

### Keyword Extraction

## ğŸ› Troubleshooting

### Frontend Issues

**Problem**: `npm install` fails

**Problem**: Port 3000 already in use

### Backend Issues

**Problem**: Import errors

**Problem**: Transformers model download slow

**Problem**: PDF parsing fails

## ğŸ“ License

MIT License - see LICENSE file for details

## ğŸ‘¥ Team CortexCoders

Built as a hackathon-ready and portfolio-worthy project demonstrating:

## ğŸ¤ Contributing

Contributions welcome! Please see CONTRIBUTING.md for guidelines.

## ğŸ“§ Support

For issues or questions:


**Happy Summarizing! ğŸ“„âœ¨**
